---
title: "BikeShareAnalysis"
author: "Razeen"
date: "2024-03-14"
output: rmarkdown::github_document
---

# Background

Cyclistic is a prominent bike-share company based in Chicago. Since its establishment in 2016, Cyclistic has expanded the services to 692 stations across Chicago with 5,824 bikes. The pricing options, including single-ride and full-day passes, alongside coveted annual memberships, offer flexibility to a diverse customer base. 

Financial analysis has affirmed the profitability of annual memberships. Therefore, this task revolves around enhancing annual memberships at Cyclistic,  to ensure its enduring success. Under the guidance of Lily Moreno, marketing director, the aim is to explore bike usage between casual riders and annual members. 

The objective is to create an effective marketing strategy that transitions casual riders into committed annual members, all underpinned by compelling data insights and visualizations.


# Objective
The objective of the analysis is to answer the following question.

- How do annual members and casual riders use Cyclistic bikes differently?


# Prepare data for Analysis
Historic data required for the analysis were to be downloaded from bike-share company dataset named Divvy.  
Following steps were taken to prepare the data for exploration.

1. Download last 12 months of rides data from [Divvy.](https://divvy-tripdata.s3.amazonaws.com/index.html) \
2. The compressed files for each month were extracted into the project folder. \
3. The CSV files were then examined to understand the size of the data as well as available variables for analysis. \ 

CSV files consist of 13 columns and thousands of observations in each file. When combined it would be over 5 million observations. Therefore, using R would be ideal to load each csv to dataframes and then combine all dataframes to a single dataframe. 


# Process the data 
## Load Packages
```{r}
library(tidyverse)
library(readr)
library(lubridate)
library(ggplot2)
# turn off scientific notations for axis
options(scipen = 999, repr.plot.width = 11, repr.plot.height = 8)
```


Loading CSV files into dataframes for each month using *read_csv* function. 
```{r readCSV}
Data202303 <- read_csv('csv_files/202303-divvy-tripdata.csv')
Data202304 <- read_csv('csv_files/202304-divvy-tripdata.csv')
Data202305 <- read_csv('csv_files/202305-divvy-tripdata.csv')
Data202306 <- read_csv('csv_files/202306-divvy-tripdata.csv')
Data202307 <- read_csv('csv_files/202307-divvy-tripdata.csv')
Data202308 <- read_csv('csv_files/202308-divvy-tripdata.csv')
Data202309 <- read_csv('csv_files/202309-divvy-tripdata.csv')
Data202310 <- read_csv('csv_files/202310-divvy-tripdata.csv')
Data202311 <- read_csv('csv_files/202311-divvy-tripdata.csv')
Data202312 <- read_csv('csv_files/202312-divvy-tripdata.csv')
Data202401 <- read_csv('csv_files/202401-divvy-tripdata.csv')
Data202402 <- read_csv('csv_files/202402-divvy-tripdata.csv')

```

Explore each dataframe for column consistency using the *structure(str)* function. 
```{r}
str(Data202303)
str(Data202304)
str(Data202305)
str(Data202306)
str(Data202307)
str(Data202308)
str(Data202309)
str(Data202310)
str(Data202311)
str(Data202312)
str(Data202401)
str(Data202402)
```

Since all columns in dataframes are identical, all dataframes can be used to merge together to form a single dataframe using *rbind*.
```{r}
MergedData <- rbind(
  Data202303, Data202304, Data202305,
  Data202306, Data202307, Data202308,
  Data202309, Data202310, Data202311,
  Data202312, Data202401, Data202402
  )
```


Check the combined dataframe created by using the *head* function.
```{r}
head(MergedData)
```

ride_id is an unique field, therefore duplicates need to be removed if there are any available. The *distinct* function can be used to perform this task. 
```{r}
NoDupMergedData <- MergedData %>% 
distinct(ride_id, .keep_all = TRUE)
```


Create a new field for ride duration as ride_duration by subtracting started_at from ended_at field. This creates a field with ride duration in seconds. 
```{r}
NoDupMergedData <- mutate(NoDupMergedData, ride_duration=ended_at-started_at)
```


create a new field for ride duration in minutes and make the type as double using *as.double* and *difftime*. 
```{r}
NoDupMergedData$ride_duration_minutes <- (as.double(difftime(NoDupMergedData$ended_at, NoDupMergedData$started_at))) /60
```


Create new fields for started hour as started_hour, day of the week as day_of_week, and month as month by using *month.name*, *weekdays*, and *hour* functions on the started_at field. 
```{r}
NoDupMergedData <- NoDupMergedData %>% 
  mutate(month = month.name[month(started_at)],
         day_of_week = weekdays(started_at),
         started_hour = hour(started_at))
```


A summary of the latest dataframe can be checked using *summary* function to explore the distribution of values in each field. 
```{r}
summary(NoDupMergedData)
```
Looking at the summary of the newly created dataframe, it is visible that there are negative values for ride_duration. The negative ride durations does not make sense. 
To check this, a subset of dataframe with negative ride duration can be creating by filtering the ride_duration_minutes for values less than 0. 

```{r}
negative_duration_df <- subset(NoDupMergedData, ride_duration_minutes < 0)
head(negative_duration_df)
```

There are 296 observations that contains negative ride durations. These needs to be removed from the main dataframe.
To do this, a subset of the main dataframe can be created using only the positive values for ride_duration_minutes by filtering values greater than 0. 

```{r}
PositiveNoDupMergedData <- subset(NoDupMergedData, ride_duration_minutes > 0)
```

Now, the main dataframe *PositiveNoDupMergedData* is ready to be analyzed after removing duplicates, parsing, filtering, and transforming the raw dataframe. 


# Analysis
Since the main dataframe is large, a smaller chunk of the dataframe can be created using the *slice* function. The smaller dataframe can be used to perform certain functions/visualizations to make sure that the function performs what is required before applying the function on the larger dataset. This is a good practice to save time when checking the results of the operation over a larger dataset. 

```{r}
datasmall <- PositiveNoDupMergedData %>%
  slice(1:1000000)
```

The total number of member and casual usage over past 12 months as a percentage of the total rides can be summarized as follows. 

```{r}
user_percentage_summary <- PositiveNoDupMergedData %>% 
  group_by(member_casual) %>% 
  summarise(count = n(),  percentage = round(length(ride_id)/nrow(PositiveNoDupMergedData)*100,2), .groups = "drop")

View(user_percentage_summary)

ggplot(user_percentage_summary, aes(x = "", y = count, fill = member_casual)) + 
  geom_col() + 
  labs(title = "Rides by User Type (Mar 2023 - Feb 2024)") + 
  geom_text(aes(label = paste(percentage, "%")), position = position_stack(vjust = 0.5), size = 4) + 
  theme_void(base_size = 12) +
  scale_fill_discrete(name = "User Type") + 
  coord_polar(theta = "y") +
  theme(plot.title = element_text(margin = margin(b = 20))) 
```

It is clear that the highest number of rides were taken by user type members with a count of 3,658,586 rides. The number of casual rides were 2,047,205.    

## Analysis by month
To further understand the distribution of bike rides by the two user types, the usage for each month can be analyzed. 
```{r}
PositiveNoDupMergedData$month <- factor(PositiveNoDupMergedData$month, levels = c("March", "April", "May", "June", "July", "August", "September", "October", "November", "December", "January", "February"))

ggplot(PositiveNoDupMergedData, aes(month, fill=member_casual)) +
  geom_bar(position="dodge", alpha=0.5) + 
  labs(title = "Rides by Month (Mar 2023 - Feb 2024)") +
  scale_fill_discrete(name = "User Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

It can be seen that the highest rides taken by the members was in August and the highest number of rides taken by casual user type was in July, From the above plot it can also be seen that there is a relation between the number of rides and the month for both user types. A gradual increase of both ride types through March to August, and a decrease of rides from August to January. 
This could be due to year end/beginning seasons as everyone celebrates holidays with Christmas and New year. It can also be due to the weather conditions during these months. To further explore the conditions, weather data can be analyzed in the particular areas of rides taken (But weather data is not included in the dataset). This is one of the important points of the analysis. 

## Analysis by day of the week
Further analysis can be made by comparing preference of day of the week by different user types throughout the 12 months. 

```{r}
PositiveNoDupMergedData$day_of_week <- factor(PositiveNoDupMergedData$day_of_week, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))


ggplot(PositiveNoDupMergedData, aes(day_of_week, fill=member_casual)) +
  geom_bar(position="dodge", alpha=0.5) + 
  labs(title = "Rides by Day of Week (Mar 2023 - Feb 2024)") +
  scale_fill_discrete(name = "User Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

It is evident that throughout all days of the week, members have the highest number of rides than casual riders. But looking at the trend of ride counts, rides taken by members are higher during weekdays compared to weekends. 
On the other hand, the rides taken by casual members are higher during the weekends and especially on Saturday. 

## Analysis of rides on weekdays

### Hour of day on weekdays

Getting the number of rides by hours on weekdays
```{r}
count_by_hours_on_weekdays <- PositiveNoDupMergedData %>%
  filter(!(day_of_week %in% c("Saturday", "Sunday")))%>%
  group_by(day_of_week, member_casual, started_hour) %>%
  summarise(count = n(), .groups = "drop")

ggplot(count_by_hours_on_weekdays, aes(x = started_hour, y = count, group = member_casual, 
  color = member_casual)) + 
  geom_point() + 
  geom_line() +
  labs(title = "Ride Count by Hour of Day on Weekdays (Mar 2023 - Feb 2024)", x = "Hour of Day", 
  y = "No. of Rides") + guides(color = guide_legend(title = "User Type")) + 
  theme(plot.title = element_text(margin = margin(b = 20))) +
  facet_wrap(~day_of_week)
```

These charts shows a common pattern in all weekdays for both user types. The charts consist of two spikes. These spikes occur between 5AM to 9AM and between 3PM to 6PM. There is clearly a correlation between time of day and bike rides. This could be due to office hours, where people use bikes to travel to and from work as well as to do some workout before and right after work. This is one of the important points of the analysis. 

### Bike type preference on weekdays

Bike type preference can be analyzed as follows. 

```{r}
bike_preference_weekdays <- PositiveNoDupMergedData %>%
  filter(!(day_of_week %in% c("Saturday", "Sunday")))%>%
  group_by(day_of_week, rideable_type, started_hour) %>%
  summarise(count = n(), .groups = "drop")

ggplot(bike_preference_weekdays, aes(x = started_hour, y = count, group = rideable_type, 
  color = rideable_type)) + 
  geom_point() + 
  geom_line() +
  labs(title = "Bike type preference by Hour of Day on Weekdays (Mar 2023 - Feb 2024)", x = "Hour of Day", 
  y = "No. of Bikes") + guides(color = guide_legend(title = "Bike Type")) + 
  theme(plot.title = element_text(margin = margin(b = 20))) +
  facet_wrap(~day_of_week) +
  scale_color_manual(values = c("classic_bike" = "yellow", "docked_bike" = "purple", "electric_bike" = "green" ))

```

The charts show that there is almost equal number of usage between classic bikes and electric bikes. 

### Ride duration on weekdays

The average ride duration time for each weekday can be analyzed as follows. 

```{r}
ride_duration_weekdays <- PositiveNoDupMergedData %>%
  filter(!(day_of_week %in% c("Saturday", "Sunday")))%>%
  group_by(day_of_week, member_casual) %>%
  summarise(avg_ride_duration = mean(ride_duration_minutes), .groups = 'drop')


ggplot(ride_duration_weekdays, aes(day_of_week, avg_ride_duration, fill = member_casual)) +
  geom_bar(position = "dodge", alpha = 0.5, stat = "identity") + 
  labs(title = "Average ride duration by Day on Weekdays (Mar 2023 - Feb 2024)",
       x = "Day of the Week",
       y = "Average Ride Duration (Minutes)") +
  scale_fill_manual(values = c("casual" = "red", "member" = "blue"), name = "User Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The chart shows that ride duration for casual members are significantly higher than members throughout the weekdays. This is one of the important points of the analysis. 

## Analysis of rides on weekends
Performing the same analysis for weekends. 
### Hour of day on weekends

Getting the number of rides by hours on weekends
```{r}

count_by_hours_on_weekends <- PositiveNoDupMergedData %>%
  filter(day_of_week %in% c("Saturday", "Sunday")) %>%
  group_by(day_of_week, member_casual, started_hour) %>%
  summarise(count = n(), .groups = "drop")

ggplot(count_by_hours_on_weekends, aes(x = started_hour, y = count, group = member_casual, 
  color = member_casual)) + 
  geom_point() + 
  geom_line() +
  labs(title = "Ride Count by Hour of Day on Weekends (Mar 2023 - Feb 2024)", x = "Hour of Day", 
  y = "No. of Rides") + guides(color = guide_legend(title = "User Type")) + 
  theme(plot.title = element_text(margin = margin(b = 20))) +
  facet_wrap(~day_of_week)

```

Bike usage by hour on weekends also shows a similar pattern for both user types But on weekends it shows a single spike of usage between hours 12 Noon to 4PM. This is one of the important points of the analysis.

### Bike type preference on weekends

```{r}
bike_preference_weekend <- PositiveNoDupMergedData %>%
  filter(day_of_week %in% c("Saturday", "Sunday"))%>%
  group_by(day_of_week, rideable_type, started_hour) %>%
  summarise(count = n(), .groups = "drop")

ggplot(bike_preference_weekend, aes(x = started_hour, y = count, group = rideable_type, 
  color = rideable_type)) + 
  geom_point() + 
  geom_line() +
  labs(title = "Bike type preference by Hour of Day on Weekends (Mar 2023 - Feb 2024)", x = "Hour of Day", 
  y = "No. of Bikes") + guides(color = guide_legend(title = "Bike Type")) + 
  theme(plot.title = element_text(margin = margin(b = 20))) +
  facet_wrap(~day_of_week) +
  scale_color_manual(values = c("classic_bike" = "yellow", "docked_bike" = "purple", "electric_bike" = "green" ))
```

As same as the usage on weekdays, the chart shows that there is almost equal number of usage between classic bikes and electric bikes.

### Ride duration on weekends

```{r}
ride_duration_weekend <- PositiveNoDupMergedData %>%
  filter(day_of_week %in% c("Saturday", "Sunday"))%>%
  group_by(day_of_week, member_casual) %>%
  summarise(avg_ride_duration = mean(ride_duration_minutes), .groups = 'drop')


ggplot(ride_duration_weekend, aes(day_of_week, avg_ride_duration, fill = member_casual)) +
  geom_bar(position = "dodge", alpha = 0.5, stat = "identity") + 
  labs(title = "Average ride duration by Day on weekends (Mar 2023 - Feb 2024)",
       x = "Day of the Week",
       y = "Average Ride Duration (Minutes)") +
  scale_fill_manual(values = c("casual" = "red", "member" = "blue"), name = "User Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Similar to the ride duration by user types on weekdays, weekend chart also shows that ride duration for casual members are significantly higher than members. This is also one of the important points of the analysis.


# Recommendations
1. recommendation 1 \
2. recommendation 2 \
3. recommendation 3 \




